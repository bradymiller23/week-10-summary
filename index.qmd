---
title: "Weekly Summary Template"
author: "Brady Miller"
title-block-banner: true
title-block-style: default
toc: true
#format: html
format: pdf
---

---

## Tuesday, March 21

::: {.callout-important}
## TIL

Include a _very brief_ summary of what you learnt in this class here. 

Today, I learnt the following concepts in class:

1. Creating decision boundaries
1. Creating and interpreting a confusion matrix
1. Multinomial Class Logistic Regression
:::

#### Decision Boundaries

```{r}
library(mlbench)
library(tidyverse)
library(nnet)
library(class)
```

```{r}
# Creating random scatterplot to create boundary on
X <- t(replicate(100,runif(2)))
y <- ifelse(apply(X,1,\(x)sum(x^1.5)) + 0.1 * rnorm(1000) <= 1, 0, 1) %>% as.factor()
col <- ifelse( y == 0, "blue", "red")

plot(X[,1], X[,2], col=col)
```

```{r}
df <- data.frame(y=y, x1 = X[,1], x2 = X[,2])
model <- glm(y~., df, family = binomial())
summary(model)
```
The summary of the model indicates that the slopes and intercepts are highly significant


```{r}
# creating a model to show for the logistic regression creates a boundary 
# separates the 2 classes and shows what it predicts at each spot
xnew <- data.frame(
  x1 = rep(seq(0,1,length.out=50),50),
  x2 = rep(seq(0,1,length.out=50),each = 50)
)

prob <- predict(model, xnew, type = 'response')
decision <- ifelse(prob<0.5, 'blue', 'red')

plot(xnew[,1], xnew[,2], col=decision, pch=22)
points(X[,1], X[,2], col=col, pch=20)
```
The decision boundary model is pretty accurate in classifying the points. There
are a few points that are misclassified but that is to be expected, as 
overfitting the decision boundary may decrease accuracy on test data



#### Confusion matrix
```{r}
idx <- sample(1:nrow(df), 100)
train <- df[-idx,]
test<- df[idx,]
model <- glm(y~., train, family = binomial())
probs <- predict(model, test, type = 'response')

predicted <- ifelse(probs<0.5, 0, 1)
expected <- test$y


table(predicted, expected)
```
How model performs on unseen data set

* 2x2 table for binary classification problem
* columns are ground truth
* first element = out of 69 people with y value 0 in test, model was able to 
correctly predict 65 of them
* out of 31 people in class 1, 29 were correctly predicted to be in class 1
* take into consideration how many false negatives/false positives your model 
  gives when determining its goodness of fit
* want 0's in the bottom left and top right columns to indicate that the model
  predicted the label of each data sample in the test set with 100% accuracy

```{r}
caret::confusionMatrix(data = as.factor(predicted), reference = as.factor(expected))
```
* gives confidence interval, p-value and other statistics that we can look at

1. Below is the elements of the confusion matrix used to calculate sensitivity 
   and specificity
* sensitivity = [1,1] / [1,1] + [2,1] 
* specificity = [2,2] / [1,2] + [2,2]



####  Multinomial Class Logistic Regression
* generalization of logistic regression for more than two 'classes'
* pick base category
  1. constructs k-1 different logistic regression models for k categories of 
     a response variable 

* use softmax function for multinomial logistic regression
 1. exponentiating every element and then normalizing it to be between 0 and 1
    by dividing it by sum of all the exponentiated classes
 2. weighted summation
 3. sum of all exponentiated elements is 1
 4. select max value to determine which class a point belongs to
 5. 0 <= exponentiated values <= 1 
 6. one-hot encoding argMax(x1,x2,...,xi,...,xk) = (0,0,...,1,...,0)
 
* softmax(0,1) = (1/(1+exp(x), exp(x)/(1+exp(x))) = (1-sigmoid(x), sigmoid(x))
 

```{r}
# create a multinomial classification problem
# want to classify a flower as one of 3 species based on petal width and petal length
 
# fix one level as reference level and then make 2 different models 

sample(1:3, size = 1000, replace = TRUE, prob=c(0.8,0.1,0.1))

b <- c(-5,0,5)
prob_function = \(x) exp(b*x) / sum(exp(b*x))

x <- rnorm(10000)
y <- c()

# sampling class labels from the data set
for (i in 1:length(x)){
  y[i] <- sample(0:2, 1, prob = prob_function(x[i]))
}

cbind(x, y) %>% head
```

```{r}
data.frame(x=x, z = rep(0, length(x)), y=y) %>% ggplot(aes(x=x, y = z, color=factor(y))) + geom_point()
``` 



```{r}
# setting level 1 as the reference level
# will compare this individually against the other class levels
df <- data.frame(x=x, y=as.factor(y))
df$y <- relevel(df$y, ref = '1')
```

```{r}
model <- nnet::multinom(y ~ x, df)
summary(model)
```
* coefficients in the first block are telling us that the intercept and slope 
  for the regression model of 0 vs 1 and 1 vs 2. 
* slope will flip signs when you switch the class level that is being used as 
  reference level






## Thursday, March 23



::: {.callout-important}
## TIL

Include a _very brief_ summary of what you learnt in this class here. 

Today, I learnt the following concepts in class:

1. More with creating decision boundaries
1. Creating and interpreting classification(decision) trees
1. Support vector machines
:::


#### Creating more decision boundaries
 
* logistic regression is useful when you want to see how a covariate is 
  affecting a response variable
```{r}
X <- t(replicate(100,2*runif(2)-1))
y <- ifelse(apply(X,1,\(x)(sum(x+0.01*rnorm(2)))) <= 0,0,1)
col <- ifelse(y == 0, "blue", "red")

plot(X[,1], X[,2], col=col, pch = 19)
```

```{r}
df <- data.frame(y=y, x1=X[,1], x2=X[,2])
model <- glm(y ~ x1 + x2, df, family = binomial())
f_logistic = \(x) predict(model, data.frame(x1=x[,1], x2 = x[,2]), type= 'response')
```

```{r}
xnew <- cbind(
  x1 = rep(seq(-1.1,1.1,length.out=50),50),
  x2 = rep(seq(-1.1,1.1,length.out=50),each = 50)
)
```

```{r}
plt <- function(f, x) {
  plot(x[,1], x[,2], col=ifelse(f(x) < 0.5, 'blue', 'red'), pch =22)
  points(df$x1, df$x2, col=ifelse(y=='0', 'blue', 'red'), pch =22)
}

overview <- function(f){
  predicted <- ifelse(f(df[,-1])<0.5, 0, 1)
  actual <- df[,1]
  table(predicted, actual)
}

plt(f_logistic, xnew)
```

#### Classification (Decision) Tree

* tries to find splits in categories
* hierarchical model that recursively partitions the data into smaller subsets 
  based on the most informative features, and each partition is associated with 
  a class label 
  
```{r}
library(rpart)
library(rpart.plot)
```


```{r}
dtree <- rpart(y ~ x1 + x2, df, method = 'class')
rpart.plot(dtree)
```
* Each split involves a question which further divides the data into smaller 
  groups
* Once the group is pure (all data samples in that group are the same) it is 
  able to classify all those by the label those data samples possess
  
```{r}
f_dtree <- \(x) as.numeric(predict(dtree, data.frame(x1 = x[,1], x2=x[,2]), type = 'class')) - 1
plt(f_dtree, xnew)
```
Creates multiple linear decision boundaries to split up the data based on what 
it predicts


```{r}
overview(f_dtree)
```
From the confusion matrix, we can see that it is pretty accurate, but has some 
errors as 6 are classified as red when it should be blue, and 3 are classified as 
blue when it should be red. 


#### Support Vector Machine

```{r}
n <- 7500
X <- t(replicate(n,2 * runif(2)-1))
y <- ifelse(apply(X,1, \(x) sum(abs(x))) + 0.1 * rnorm(n) <= 1, 0, 1) %>% as.factor()
col <- ifelse(y==0, 'blue', 'red') 
df <- data.frame(y=y, x1=X[,1], x2=X[,2]) 
  
plot(X[,1], X[,2], col=col, pch=19)
```


```{r}
library(e1071)
```

```{r}
svm_model <- svm(y~x1+x2, df, kernel = 'radial')
summary(svm_model)
```


```{r}
f_svm <- \(x) predict(svm_model, x) %>% as.factor() - 1
plt(f_svm, xnew)
```
Shows the model that predicts what each data sample would be labeled at each
spot on the graph. You can see that it is pretty similar to the original 
graph we created with the assigned red and blue points in the diamond formation.
